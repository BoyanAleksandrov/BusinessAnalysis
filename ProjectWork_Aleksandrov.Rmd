---
title:    "TDS10 Final Project"
author:   
- "Aleksandrov Boyan, 320961, b.aleksandrov@studenti.luiss.it"
- "Nishtelkova Maria"

abstract: "IF you wish, you may add here a short abstract of 100 words max."
date:     "Last compiled on:   `r format(Sys.time(), '%d %B, %Y')`"
output:   pdf_document
fontsize: 12pt
header-includes:
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{lmodern}
  \usepackage{lipsum}
  \usepackage{fancyhdr}
  \pagestyle{fancy}
  \renewcommand{\headrulewidth}{0pt}
  \fancyhf{}
  \fancyfoot[C]{\twopagenumbers}
  \fancypagestyle{plain}{
    \renewcommand{\headrulewidth}{0pt}
    \fancyhf{}
    \fancyfoot[C]{\twopagenumbers}
  }
  \usepackage[user]{zref}
  \newcounter{pageaux}
  \def\currentauxref{PAGEAUX1}
  \newcommand{\twopagenumbers}{
    \stepcounter{pageaux}
    \thepageaux\, of\, \ref{\currentauxref}
  }
  \makeatletter
  \newcommand{\resetpageaux}{
    \clearpage
    \edef\@currentlabel{\thepageaux}\label{\currentauxref}
    \xdef\currentauxref{PAGEAUX\thepage}
    \setcounter{pageaux}{0}}
  \AtEndDvi{\edef\@currentlabel{\thepageaux}\label{\currentauxref}}
  \makeatletter
---

# Introduction

"adsadsds"


# Dataset Description

(Write about heart.csv here)


# Data Preparation
```{r}
heartData <- read.csv("heart.csv")
head(heartData)
```
read.csv()

# Exploratory Data Analysis
There are several variables in the dataset containing missing values.In order to prepare the data for the multinomial logistic model,we observed how many missing values each variable had and saw that the variables ca, thal, and slope had extremely high numbers of missing values. Because these variables are categorical, and because imputing such a large amount of missing data would introduce strong bias, we decided to remove them from the dataset.
For the remaining numeric variables with less missing values- (trestbps, chol, thalach, oldpeak) we applied median imputation.

We chose this method because replacing each missing value with the median of the corresponding variable is a robust measure that is not affected by extreme values. 

For the categorial variables with very few missing values, we replaced missing entries with the most frequent category (the mode).

This approach ensures that there are no missing values before using the multinomial logistic regression model.

# Multinomial Logistic Regression â€” Theory

Question(1.1):

We are using multinomial Logistic Regression because the response variable can take more than 2 categories.
For these categories there is a separate set of coefficients and we choose one as the baseline. The coefficients
describe how the predictors(age, sex, chol etc.) affect the probability of belonging to each outcome category.

In this regression the response variable Y can take K-number of different categories.
We have to pick one of the categories to be the baseline - category 0, for every other category - k = 1,2...,K-1.

The model shows the probability of an observation belonging to category K using the multinomial logistic regression function:

$$
P(Y = k \mid X) =
\frac{\exp(\beta_{0k} + \beta_k^T X)}
     {1 + \sum_{j=1}^{K-1} \exp(\beta_{0j} + \beta_j^T X)}
$$

The probability of the baseline category is:

$$
P(Y = 0 \mid X) =
\frac{1}
     {1 + \sum_{j=1}^{K-1} \exp(\beta_{0j} + \beta_j^T X)}
$$

# Multinomial Logistic Regression

(Fit model + interpretation)

# Model Evaluation

(Cross-validation)

# Model Improvement

(Stepwise model / alternative model)

# Binary Logistic Regression

(Create hdc01 + logistic model)

# Model Comparison

(Compare multinomial vs binary)

# Conclusion

(Brief summary)

