---
title:    "TDS10 Final Project"
author:   
- "Aleksandrov Boyan, 320961, b.aleksandrov@studenti.luiss.it"
- "Nishtelkova Maria"

abstract: "IF you wish, you may add here a short abstract of 100 words max."
date:     "Last compiled on:   `r format(Sys.time(), '%d %B, %Y')`"
output:   
  pdf_document:
    fig_crop: true
fontsize: 12pt
header-includes:
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{lmodern}
  \usepackage{lipsum}
  \usepackage{fancyhdr}
  \usepackage{float} 
  \pagestyle{fancy}
  \renewcommand{\headrulewidth}{0pt}
  \fancyhf{}
  \fancyfoot[C]{\twopagenumbers}
  \fancypagestyle{plain}{
    \renewcommand{\headrulewidth}{0pt}
    \fancyhf{}
    \fancyfoot[C]{\twopagenumbers}
  }
  \usepackage[user]{zref}
  \newcounter{pageaux}
  \def\currentauxref{PAGEAUX1}
  \newcommand{\twopagenumbers}{
    \stepcounter{pageaux}
    \thepageaux\, of\, \ref{\currentauxref}
  }
  \makeatletter
  \newcommand{\resetpageaux}{
    \clearpage
    \edef\@currentlabel{\thepageaux}\label{\currentauxref}
    \xdef\currentauxref{PAGEAUX\thepage}
    \setcounter{pageaux}{0}}
  \AtEndDvi{\edef\@currentlabel{\thepageaux}\label{\currentauxref}}
  \makeatletter
---



# Introduction

"adsadsds"


9999999






After restecg vs hdc barplot:
Some Rest ECG categories show different frequencies across hdc levels, indicating a possible relationship.


hist
Histograms show the distribution of the numeric variables. Some variables are skewed (especially oldpeak), and the plots help us understand the data before modeling.

# Dataset Description

(Write about heart.csv here)


# Multinomial Logistic Regression â€” Theory

Question(1.1):

We are using multinomial Logistic Regression because the response variable can take more than 2 categories.
For these categories there is a separate set of coefficients and we choose one as the baseline. The coefficients
describe how the predictors(age, sex, chol etc.) affect the probability of belonging to each outcome category.

In this regression the response variable Y can take K-number of different categories.
We have to pick one of the categories to be the baseline - category 0, for every other category - k = 1,2...,K-1.

The model shows the probability of an observation belonging to category K using the multinomial logistic regression function:

$$
P(Y = k \mid X) =
\frac{\exp(\beta_{0k} + \beta_k^T X)}
     {1 + \sum_{j=1}^{K-1} \exp(\beta_{0j} + \beta_j^T X)}
$$

The probability of the baseline category is:

$$
P(Y = 0 \mid X) =
\frac{1}
     {1 + \sum_{j=1}^{K-1} \exp(\beta_{0j} + \beta_j^T X)}
$$


# Data Preparation 

There are several variables in the dataset containing missing values.In order to prepare the data for the multinomial logistic model,we observed how many missing values each variable had and saw that the variables ca, thal, and slope had extremely high numbers of missing values. Because these variables are categorical, and because imputing such a large amount of missing data would introduce strong bias, we decided to remove them from the dataset.
For the remaining numeric variables with less missing values- (trestbps, chol, thalach, oldpeak) we applied median imputation.

We chose this method because replacing each missing value with the median of the corresponding variable is a robust measure that is not affected by extreme values. 

For the categorial variables with very few missing values, we replaced missing entries with the most frequent category (the mode).

This approach ensures that there are no missing values before using the multinomial logistic regression model.

```{r, echo=FALSE}

heartData <- read.csv("heart.csv")

# Convert to character before imputation
heartData$place   <- as.character(heartData[["place"]])
heartData$cp      <- as.character(heartData[["cp"]])
heartData$restecg <- as.character(heartData[["restecg"]])

# Convert target to factor
heartData$hdc     <- as.factor(heartData[["hdc"]])

# Convert sex, fbs, exang to numeric 0/1
heartData$sex   <- ifelse(heartData[["sex"]] == "Male", 1, 0)
heartData$fbs   <- ifelse(heartData$fbs, 1, 0)
heartData$exang <- ifelse(heartData$exang, 1, 0)

# Numeric imputation (includes fbs and exang!)
heartData$trestbps[is.na(heartData$trestbps)] <- median(heartData$trestbps, na.rm = TRUE)
heartData$chol[is.na(heartData$chol)] <- median(heartData$chol, na.rm = TRUE)
heartData$thalch[is.na(heartData$thalch)] <- median(heartData$thalch, na.rm = TRUE)
heartData$oldpeak[is.na(heartData$oldpeak)] <- median(heartData$oldpeak, na.rm = TRUE)

# Impute missing fbs and exang numerically
heartData$fbs[is.na(heartData$fbs)]     <- median(heartData$fbs, na.rm = TRUE)
heartData$exang[is.na(heartData$exang)] <- median(heartData$exang, na.rm = TRUE)

# Remove high-missing columns
heartData$ca    <- NULL
heartData$thal  <- NULL
heartData$slope <- NULL

# Mode imputation for character variables
mostCommon_place <- names(sort(table(heartData$place), decreasing = TRUE))[1]
heartData$place[is.na(heartData$place)] <- mostCommon_place

mostCommon_cp <- names(sort(table(heartData$cp), decreasing = TRUE))[1]
heartData$cp[is.na(heartData$cp)] <- mostCommon_cp

mostCommon_restecg <- names(sort(table(heartData$restecg), decreasing = TRUE))[1]
heartData$restecg[is.na(heartData$restecg)] <- mostCommon_restecg

# Convert cleaned categories to factors
heartData$place   <- as.factor(heartData$place)
heartData$cp      <- as.factor(heartData$cp)
heartData$restecg <- as.factor(heartData$restecg)

# Final check
colSums(is.na(heartData))
head(heartData)


```


# Exploratory Data Analysis


Before establishing the multinomial logistic regression model, we looked at some of the predictors' visual variations over the response variable hdc's various levels. This enables us to recognise potential patterns and comprehend which factors might be helpful in predicting the seriousness of heart disease.

To investigate numerical factors like cholesterol, resting blood pressure, maximal heart rate, and ST depression, we employed boxplots. These charts illustrate the variations in these variables' distributions among the various categories of heart disease.

To determine how the frequency of each category varies throughout the hdc levels, we made barplots for categorical variables including the type of chest discomfort and the resting ECG result.

An introductory comprehension of the connections between predictors and the response variable is provided by this visual investigation.


Cholesterol levels across heart disease categories
Cholesterol levels appear broadly similar across categories, though higher HDC groups show slightly more variability.
```{r chol_plot, fig.pos='H', fig.height=4, fig.width=5, out.extra='clip', echo=FALSE}

library(ggplot2)
ggplot(heartData, aes(x = factor(hdc), y = chol, fill = factor(hdc))) +
  geom_boxplot(alpha = 0.7) +
  labs(x = "HDC", y = "Cholesterol",
       title = "Cholesterol levels across heart disease categories") +
  theme_minimal() +
  theme(legend.position = "none")
```


Resting blood pressure across heart disease categories
Resting blood pressure shows a mild increasing trend with higher HDC, but overall differences between groups are modest.

```{r rest_plot, fig.pos='H', fig.height=4, fig.width=5, out.extra='clip', echo=FALSE}
ggplot(heartData, aes(x = factor(hdc), y = trestbps, fill = factor(hdc))) +
  geom_boxplot(alpha = 0.7) +
  labs(x = "HDC", y = "Resting Blood Pressure",
       title = "Resting blood pressure across heart disease categories") +
  theme_minimal() +
  theme(legend.position = "none")

```

Maximum heart rate across heart disease categories
Patients with higher HDC values generally demonstrate lower maximum heart rates compared to those without heart disease.

```{r mheart_plot, fig.pos='H', fig.height=4, fig.width=5, out.extra='clip', echo=FALSE}
ggplot(heartData, aes(x = factor(hdc), y = thalch, fill = factor(hdc))) +
  geom_boxplot(alpha = 0.7) +
  labs(x = "HDC", y = "Maximum heart level",
       title = "Maximum heart level across heart disease categories") +
  theme_minimal() +
  theme(legend.position = "none")
```

Proportion of heart disease category by chest pain type
Atypical and non-anginal chest pain types contain a higher proportion of severe heart disease cases compared to typical angina.


```{r cp_plot, fig.pos='H', fig.height=4, fig.width=5, out.extra='clip', echo=FALSE}
ggplot(heartData, aes(x = cp, fill = factor(hdc))) +
  geom_bar(position = "fill") +
  labs(x = "Chest Pain Type",
       y = "Proportion",
       title = "Proportion of heart disease category by chest pain type",
       fill = "hdc") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

Proportion of heart disease category by resting ECG type
ST-T abnormalities and LV hypertrophy are associated with a greater share of higher heart disease categories compared to normal ECG results.

```{r ecg_plot, fig.pos='H', fig.height=4, fig.width=5, out.extra='clip', echo=FALSE}
ggplot(heartData, aes(x = restecg, fill = factor(hdc))) +
  geom_bar(position = "fill") +
  labs(x = "Resting ECG Type",
       y = "Proportion",
       title = "Proportion of heart disease category by resting ECG",
       fill = "hdc") +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

Distribution of age across HDC
Patients with higher heart disease categories tend to be older, with the age distribution shifting toward later decades as HDC increases.

```{r age_plot, fig.pos='H', fig.height=4, fig.width=5, out.extra='clip', echo=FALSE}
ggplot(heartData, aes(x = age, fill = factor(hdc))) +
  geom_histogram(alpha = 0.7, position = "identity", bins = 40) +
  labs(
    x = "Age",
    y = "Count",
    fill = "HDC",
    title = "Distribution of age across HDC"
  ) +
  theme_minimal()

```
By looking at the box plot and p-test results we can conclude that we do not have statistically significant evidence that males and females have different mean ages.

With the p-test being bellow 0.05, we get the confirmation that the difference is not strong enough to be called significant.

```{r}

boxplot(age ~ sex, data = heartData,
        names = c("Female", "Male"),
        main = "Age Distribution by Sex",
        xlab = "Sex",
        ylab = "Age")

t.test(age ~ sex, data = heartData)


```
# Multinomial Logistic Regression

We decided to fit the regression model using multinom() from the nnet, with hdc as the target variable and we included all of the predictors.

The baseline category is choosen to be hdc = 0 and for each other category hdc = 1-4 the model estimates how much each predictor affects the odds of belonging to a category 1-4 versus the baseline.

Multiple predictors appear as strong.
Sex has a positive coefficient, indicating that males have higher chance of heart disease compared to females.
Another one is exang. It increases the odds of being in any of the disease categories 1-4.
In addition cp has a large negative indicating that certain chest pains reduces the risk of higher disease categories.

Overall the model selects oldpeak, exang, cp and maximum heart rate as key predictors 

```{r, message=FALSE, echo=TRUE, results='hide', warning=FALSE}

library(nnet)
multinomial_regression <- multinom(
  hdc ~ age + sex + place +chol + cp + trestbps
  +fbs + restecg + thalch + exang + oldpeak,
  data = heartData
)

summary(multinomial_regression)

```
# Model Evaluation

```{r}
students <- data.frame(
  name = c("Boyan Aleksandrov", "Maria Nishtelkova", "John Doe"),
  date = as.Date(c("11-12-2001", "14-12-2002", "09-07-2003"), format = "%d-%m-%Y")
)

distance <- as.Date("21-08-2020", format="%d-%m-%Y")

students$days_to_distance <- sapply(students$date, function(studentsData) {
  studentsData <- format(studentsData, "%d-%m-%Y")
  students_split <- unlist(strsplit(studentsData, "-"))
  birth <- as.Date(
    paste(students_split[1], students_split[2], "2020", sep = "-"),
    format = "%d-%m-%Y"
  )
  abs(as.numeric(birth - distance))
})

closest_student <- which.min(students$days_to_distance)
chosen <- students[closest_student,]

cat("Selected:", chosen$name, "\n")

seed_val <- as.numeric(format(chosen$date, "%d%m%Y"))
set.seed(seed_val)

cat("Seed is:", seed_val, "\n")

cv_methods <- c(
  "Vanilla validation set",
  "K-Fold (K = 5)",
  "K-Fold (K = 10)",
  "LOO-CV"
)

CV_choice <- sample(cv_methods, 1)
cat("CV Method:", CV_choice, "\n")

# Define n ONCE for all CV choices
n <- nrow(heartData)


if (CV_choice == "Vanilla validation set") {
  
  set.seed(seed_val)
  trainIndices <- sample(seq_len(n), size = round(0.7 * n))
  
  train_set <- heartData[trainIndices, ]
  test_set  <- heartData[-trainIndices, ]
  

  train_set$hdc <- factor(train_set$hdc)
  test_set$hdc  <- factor(test_set$hdc)
  
  multinom_cv <- multinom(
    hdc ~ age + sex + place + chol + cp + trestbps +
      fbs + restecg + thalch + exang + oldpeak,
    data = train_set,
    trace = FALSE
  )
  
  pred <- predict(multinom_cv, test_set)
  
  accuracy <- mean(pred == test_set$hdc)
  err <- 1 - accuracy
  
  cat("Accuracy:", round(accuracy, 3), " Error rate:", round(err, 3), "\n")
}


if (CV_choice == "LOO-CV") {
  
  loocv_preds <- vector("character", n)
  
  for (i in seq_len(n)) {
    train_set <- heartData[-i, ]
    test_set  <- heartData[i, , drop = FALSE]
    
    train_set$hdc <- factor(train_set$hdc)
    test_set$hdc  <- factor(test_set$hdc)
    
    multinom_cv <- multinom(
      hdc ~ age + sex + place + chol + cp + trestbps +
        fbs + restecg + thalch + exang + oldpeak,
      data = train_set,
      trace = FALSE
    )
    
    loocv_preds[i] <- predict(multinom_cv, test_set)
  }
  
  acc_loocv <- mean(loocv_preds == heartData$hdc)
  err_loocv <- 1 - acc_loocv
  
  cat("Accuracy:", round(acc_loocv, 3), " Error:", round(err_loocv, 3), "\n")
}

if (CV_choice == "K-Fold (K = 5)") {
  
  K <- 5
  fold_ids <- sample(rep(1:K, length.out = n))
  kfold_preds <- vector("character", n)
  
  for (k in 1:K) {
    
    train_set <- heartData[fold_ids != k, ]
    test_set  <- heartData[fold_ids == k, ]
    
    train_set$hdc <- factor(train_set$hdc)
    test_set$hdc  <- factor(test_set$hdc)
    
    multinom_cv <- multinom(
      hdc ~ age + sex + place + chol + cp + trestbps +
        fbs + restecg + thalch + exang + oldpeak,
      data = train_set,
      trace = FALSE
    )
    
    kfold_preds[fold_ids == k] <- predict(multinom_cv, test_set)
  }
  
  acc_kfold5 <- mean(kfold_preds == heartData$hdc)
  err_kfold5 <- 1 - acc_kfold5
  
  cat("Accuracy:", round(acc_kfold5, 3), " Error:", round(err_kfold5, 3), "\n")
}


if (CV_choice == "K-Fold (K = 10)") {
  
  K <- 10
  fold_ids <- sample(rep(1:K, length.out = n))
  kfold_preds <- vector("character", n)
  
  for (k in 1:K) {
    
    train_set <- heartData[fold_ids != k, ]
    test_set  <- heartData[fold_ids == k, ]
    
    train_set$hdc <- factor(train_set$hdc)
    test_set$hdc  <- factor(test_set$hdc)
    
    multinom_cv <- multinom(
      hdc ~ age + sex + place + chol + cp + trestbps +
        fbs + restecg + thalch + exang + oldpeak,
      data = train_set,
      trace = FALSE
    )
    
    kfold_preds[fold_ids == k] <- predict(multinom_cv, test_set)
  }
  
  acc_kfold10 <- mean(kfold_preds == heartData$hdc)
  err_kfold10 <- 1 - acc_kfold10
  
  cat("Accuracy:", round(acc_kfold10, 3), " Error:", round(err_kfold10, 3), "\n")
}

```
# Model Improvement

(Stepwise model / alternative model)

# Binary Logistic Regression

(Create hdc01 + logistic model)

# Model Comparison

(Compare multinomial vs binary)

# Conclusion

(Brief summary)

